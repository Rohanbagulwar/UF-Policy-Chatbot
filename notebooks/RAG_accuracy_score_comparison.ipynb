{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d482ef41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas\n",
      "  Downloading ragas-0.3.9-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.21.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (2.2.6)\n",
      "Collecting tiktoken (from ragas)\n",
      "  Downloading tiktoken-0.12.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (2.12.3)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Collecting appdirs (from ragas)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting diskcache>=5.6.3 (from ragas)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: typer in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (0.20.0)\n",
      "Requirement already satisfied: rich in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (14.2.0)\n",
      "Requirement already satisfied: openai>=1.0.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (2.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (4.67.1)\n",
      "Collecting instructor (from ragas)\n",
      "  Downloading instructor-1.13.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitpython (from ragas)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pillow>=10.4.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (12.0.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (3.4.2)\n",
      "Collecting scikit-network (from ragas)\n",
      "  Downloading scikit_network-0.33.4-cp310-cp310-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: langchain in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (1.0.0)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from ragas) (1.0.0)\n",
      "Collecting langchain-community (from ragas)\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain_openai (from ragas)\n",
      "  Downloading langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: click in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from nltk) (2025.10.23)\n",
      "Requirement already satisfied: filelock in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py310-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from openai>=1.0.0->ragas) (0.11.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from openai>=1.0.0->ragas) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic>=2.0.0->ragas) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from tqdm->ragas) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython->ragas)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->ragas)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor->ragas)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from instructor->ragas) (3.1.6)\n",
      "Collecting pre-commit>=4.3.0 (from instructor->ragas)\n",
      "  Downloading pre_commit-4.4.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from instructor->ragas) (9.1.2)\n",
      "Collecting ty>=0.0.1a23 (from instructor->ragas)\n",
      "  Downloading ty-0.0.1a27-py3-none-win_amd64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from rich->ragas) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from rich->ragas) (2.19.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from typer->ragas) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
      "Collecting cfgv>=2.0.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
      "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting identify>=1.0.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
      "  Downloading identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nodeenv>=0.11.1 (from pre-commit>=4.3.0->instructor->ragas)\n",
      "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting virtualenv>=20.10.0 (from pre-commit>=4.3.0->instructor->ragas)\n",
      "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas)\n",
      "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor->ragas) (4.5.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain->ragas) (1.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-core->ragas) (0.4.37)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain->ragas) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain->ragas) (1.0.0)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langgraph<1.1.0,>=1.0.0->langchain->ragas) (0.2.9)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain->ragas) (1.11.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain->ragas) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->ragas) (0.25.0)\n",
      "Collecting langchain-core (from ragas)\n",
      "  Downloading langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community->ragas)\n",
      "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community->ragas)\n",
      "  Downloading sqlalchemy-2.0.44-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community->ragas)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community->ragas)\n",
      "  Downloading pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community->ragas)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community->ragas) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas) (1.1.1)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community->ragas)\n",
      "  Downloading greenlet-3.2.4-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->ragas)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: scipy>=1.7.3 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from scikit-network->ragas) (1.15.3)\n",
      "Downloading ragas-0.3.9-py3-none-any.whl (366 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.8 MB/s  0:00:00\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading multiprocess-0.70.18-py310-none-any.whl (134 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading pyarrow-22.0.0-cp310-cp310-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/28.1 MB 4.2 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.6/28.1 MB 4.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.4/28.1 MB 3.9 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 3.1/28.1 MB 3.9 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.9/28.1 MB 3.8 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.7/28.1 MB 3.9 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.8/28.1 MB 4.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.8/28.1 MB 4.1 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 7.9/28.1 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 9.2/28.1 MB 4.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 10.5/28.1 MB 4.6 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 11.8/28.1 MB 4.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 12.8/28.1 MB 4.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 14.2/28.1 MB 4.9 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 15.5/28.1 MB 5.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 16.8/28.1 MB 5.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 18.4/28.1 MB 5.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 19.4/28.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 20.4/28.1 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.8/28.1 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 23.3/28.1 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.6/28.1 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 26.0/28.1 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.3/28.1 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.0/28.1 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 5.3 MB/s  0:00:05\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading instructor-1.13.0-py3-none-any.whl (160 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading pre_commit-4.4.0-py2.py3-none-any.whl (226 kB)\n",
      "Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
      "Downloading identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
      "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
      "Downloading ty-0.0.1a27-py3-none-win_amd64.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/9.6 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/9.6 MB 6.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.9/9.6 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.2/9.6 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.6/9.6 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.9/9.6 MB 6.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.2/9.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 6.2 MB/s  0:00:01\n",
      "Downloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
      "   ---------------------------------------- 0.0/6.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.6/6.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.4/6.0 MB 9.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.5/6.0 MB 7.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.8/6.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.0/6.0 MB 6.0 MB/s  0:00:00\n",
      "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
      "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 5.4 MB/s  0:00:00\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 0.8/1.0 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 3.6 MB/s  0:00:00\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-1.0.5-py3-none-any.whl (471 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.3/2.1 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 7.0 MB/s  0:00:00\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading greenlet-3.2.4-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading langchain_openai-1.0.3-py3-none-any.whl (82 kB)\n",
      "Downloading tiktoken-0.12.0-cp310-cp310-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 879.4/879.4 kB 5.6 MB/s  0:00:00\n",
      "Downloading scikit_network-0.33.4-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 1.6/2.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 6.9 MB/s  0:00:00\n",
      "Installing collected packages: distlib, appdirs, virtualenv, ty, smmap, pyarrow, nodeenv, mypy-extensions, marshmallow, identify, httpx-sse, greenlet, docstring-parser, diskcache, dill, cfgv, async-timeout, typing-inspect, tiktoken, SQLAlchemy, scikit-network, pre-commit, nltk, multiprocess, gitdb, pydantic-settings, gitpython, dataclasses-json, langchain-core, instructor, datasets, langchain_openai, langchain-classic, langchain-community, ragas\n",
      "\n",
      "   -- -------------------------------------  2/35 [virtualenv]\n",
      "   -- -------------------------------------  2/35 [virtualenv]\n",
      "   -- -------------------------------------  2/35 [virtualenv]\n",
      "   ---- -----------------------------------  4/35 [smmap]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   ----- ----------------------------------  5/35 [pyarrow]\n",
      "   --------- ------------------------------  8/35 [marshmallow]\n",
      "   ------------ --------------------------- 11/35 [greenlet]\n",
      "   ------------ --------------------------- 11/35 [greenlet]\n",
      "   ------------- -------------------------- 12/35 [docstring-parser]\n",
      "   ---------------- ----------------------- 14/35 [dill]\n",
      "   ---------------- ----------------------- 14/35 [dill]\n",
      "  Attempting uninstall: async-timeout\n",
      "   ---------------- ----------------------- 14/35 [dill]\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "   ---------------- ----------------------- 14/35 [dill]\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "   ---------------- ----------------------- 14/35 [dill]\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "   ---------------- ----------------------- 14/35 [dill]\n",
      "   -------------------- ------------------- 18/35 [tiktoken]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   --------------------- ------------------ 19/35 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 20/35 [scikit-network]\n",
      "   ---------------------- ----------------- 20/35 [scikit-network]\n",
      "   ---------------------- ----------------- 20/35 [scikit-network]\n",
      "   ---------------------- ----------------- 20/35 [scikit-network]\n",
      "   ---------------------- ----------------- 20/35 [scikit-network]\n",
      "   ---------------------- ----------------- 20/35 [scikit-network]\n",
      "   ------------------------ --------------- 21/35 [pre-commit]\n",
      "   ------------------------ --------------- 21/35 [pre-commit]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   ------------------------- -------------- 22/35 [nltk]\n",
      "   -------------------------- ------------- 23/35 [multiprocess]\n",
      "   -------------------------- ------------- 23/35 [multiprocess]\n",
      "   ---------------------------- ----------- 25/35 [pydantic-settings]\n",
      "   ----------------------------- ---------- 26/35 [gitpython]\n",
      "   ------------------------------ --------- 27/35 [dataclasses-json]\n",
      "  Attempting uninstall: langchain-core\n",
      "   ------------------------------ --------- 27/35 [dataclasses-json]\n",
      "    Found existing installation: langchain-core 1.0.0\n",
      "   ------------------------------ --------- 27/35 [dataclasses-json]\n",
      "    Uninstalling langchain-core-1.0.0:\n",
      "   ------------------------------ --------- 27/35 [dataclasses-json]\n",
      "   -------------------------------- ------- 28/35 [langchain-core]\n",
      "      Successfully uninstalled langchain-core-1.0.0\n",
      "   -------------------------------- ------- 28/35 [langchain-core]\n",
      "   -------------------------------- ------- 28/35 [langchain-core]\n",
      "   -------------------------------- ------- 28/35 [langchain-core]\n",
      "   -------------------------------- ------- 28/35 [langchain-core]\n",
      "   -------------------------------- ------- 28/35 [langchain-core]\n",
      "   -------------------------------- ------- 28/35 [langchain-core]\n",
      "   --------------------------------- ------ 29/35 [instructor]\n",
      "   --------------------------------- ------ 29/35 [instructor]\n",
      "   --------------------------------- ------ 29/35 [instructor]\n",
      "   ---------------------------------- ----- 30/35 [datasets]\n",
      "   ---------------------------------- ----- 30/35 [datasets]\n",
      "   ---------------------------------- ----- 30/35 [datasets]\n",
      "   ---------------------------------- ----- 30/35 [datasets]\n",
      "   ----------------------------------- ---- 31/35 [langchain_openai]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------ --- 32/35 [langchain-classic]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   ------------------------------------- -- 33/35 [langchain-community]\n",
      "   -------------------------------------- - 34/35 [ragas]\n",
      "   -------------------------------------- - 34/35 [ragas]\n",
      "   -------------------------------------- - 34/35 [ragas]\n",
      "   -------------------------------------- - 34/35 [ragas]\n",
      "   ---------------------------------------- 35/35 [ragas]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.44 appdirs-1.4.4 async-timeout-4.0.3 cfgv-3.4.0 dataclasses-json-0.6.7 datasets-4.4.1 dill-0.4.0 diskcache-5.6.3 distlib-0.4.0 docstring-parser-0.17.0 gitdb-4.0.12 gitpython-3.1.45 greenlet-3.2.4 httpx-sse-0.4.3 identify-2.6.15 instructor-1.13.0 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.0.5 langchain_openai-1.0.3 marshmallow-3.26.1 multiprocess-0.70.18 mypy-extensions-1.1.0 nltk-3.9.2 nodeenv-1.9.1 pre-commit-4.4.0 pyarrow-22.0.0 pydantic-settings-2.12.0 ragas-0.3.9 scikit-network-0.33.4 smmap-5.0.2 tiktoken-0.12.0 ty-0.0.1a27 typing-inspect-0.9.0 virtualenv-20.35.4\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas nltk datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8435d6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from rouge_score) (3.9.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from rouge_score) (2.2.6)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from nltk->rouge_score) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from nltk->rouge_score) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from nltk->rouge_score) (2025.10.23)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from click->nltk->rouge_score) (0.4.6)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py): started\n",
      "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=25027 sha256=90694e861ed57adf710955b8356417af74a161b61bbb43cea31927713a9d6872\n",
      "  Stored in directory: c:\\users\\rohan\\appdata\\local\\pip\\cache\\wheels\\5f\\dd\\89\\461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: absl-py, rouge_score\n",
      "\n",
      "   -------------------- ------------------- 1/2 [rouge_score]\n",
      "   ---------------------------------------- 2/2 [rouge_score]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 rouge_score-0.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3923d4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI client created successfully\n",
      "  Base URL: https://api.ai.it.ufl.edu\n",
      "  Client type: <class 'openai.OpenAI'>\n",
      "  Has chat attribute: True\n",
      "  Has completions attribute: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from clients.openai_client import OpenAIClientManager\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "# Download NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "from config import OpenAIConfig\n",
    "# Initialize LLM for RAGAS (you can use OpenAI or other providers)\n",
    "llm = OpenAIClientManager(OpenAIConfig).initialize()\n",
    "embeddings = SentenceTransformer(\"./bge-small\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3bda985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu_score(reference, candidate):\n",
    "    \"\"\"Calculate BLEU score between reference and candidate answers\"\"\"\n",
    "    try:\n",
    "        # Handle NaN or None values\n",
    "        if pd.isna(reference) or pd.isna(candidate):\n",
    "            return 0.0\n",
    "        \n",
    "        reference_tokens = str(reference).lower().split()\n",
    "        candidate_tokens = str(candidate).lower().split()\n",
    "        \n",
    "        # Use smoothing function to avoid zero scores\n",
    "        smoothie = SmoothingFunction().method4\n",
    "        score = sentence_bleu([reference_tokens], candidate_tokens, \n",
    "                             smoothing_function=smoothie)\n",
    "        return round(score, 4)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating BLEU score: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99fbeaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge_scores(reference, candidate):\n",
    "    \"\"\"Calculate ROUGE-1, ROUGE-2, and ROUGE-L scores\"\"\"\n",
    "    try:\n",
    "        if pd.isna(reference) or pd.isna(candidate):\n",
    "            return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}\n",
    "        \n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = scorer.score(str(reference), str(candidate))\n",
    "        \n",
    "        return {\n",
    "            'rouge1': round(scores['rouge1'].fmeasure, 4),\n",
    "            'rouge2': round(scores['rouge2'].fmeasure, 4),\n",
    "            'rougeL': round(scores['rougeL'].fmeasure, 4)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b0a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_meteor_score(reference, candidate):\n",
    "    \"\"\"Calculate METEOR score\"\"\"\n",
    "    try:\n",
    "        if pd.isna(reference) or pd.isna(candidate):\n",
    "            return 0.0\n",
    "        \n",
    "        reference_tokens = str(reference).lower().split()\n",
    "        candidate_tokens = str(candidate).lower().split()\n",
    "        \n",
    "        score = meteor_score([reference_tokens], candidate_tokens)\n",
    "        return round(score, 4)\n",
    "    except Exception as e:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e0c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answers(excel_file, sheet_name='Sheet1' \n",
    "                    ):\n",
    "    \"\"\"\n",
    "    Evaluate answers from Excel sheet with BLEU, ROUGE, METEOR, and Perplexity\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    excel_file : str\n",
    "        Path to Excel file\n",
    "    sheet_name : str\n",
    "        Name of the sheet to read\n",
    "    calculate_ppl : bool\n",
    "        Whether to calculate perplexity (slower)\n",
    "    ppl_model_name : str\n",
    "        Model to use for perplexity calculation (e.g., \"gpt2\", \"gpt2-medium\")\n",
    "    use_gpu : bool\n",
    "        Whether to use GPU for perplexity calculation\n",
    "    \n",
    "    Expected columns: Question, Human_Answer, gpt_oss, llama_answer, gemma_answer\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "    \n",
    "    print(f\" Loaded {len(df)} rows from Excel\")\n",
    "    print(f\" Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Standardize column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    column_mapping = {}\n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if 'question' in col_lower:\n",
    "            column_mapping[col] = 'Question'\n",
    "        elif 'human' in col_lower and 'answer' in col_lower:\n",
    "            column_mapping[col] = 'Human_Answer'\n",
    "        elif 'gpt' in col_lower or 'oss' in col_lower:\n",
    "            column_mapping[col] = 'GPT_Answer'\n",
    "        elif 'llama' in col_lower:\n",
    "            column_mapping[col] = 'Llama_Answer'\n",
    "        elif 'gemma' in col_lower:\n",
    "            column_mapping[col] = 'Gemma_Answer'\n",
    "    \n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "    print(f\" Standardized columns: {df.columns.tolist()}\\n\")\n",
    "    \n",
    "    # Identify model columns\n",
    "    model_columns = [col for col in df.columns if col.endswith('_Answer') and col != 'Human_Answer']\n",
    "    models = [col.replace('_Answer', '') for col in model_columns]\n",
    "    \n",
    "    print(f\" Found models: {models}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ==================== CALCULATE METRICS ====================\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"CALCULATING METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for model in models:\n",
    "        model_col = f'{model}_Answer'\n",
    "        \n",
    "        print(f\"\\n Evaluating {model}...\")\n",
    "        \n",
    "        # BLEU Score\n",
    "        print(\"   → BLEU...\")\n",
    "        df[f'BLEU_{model}'] = df.apply(\n",
    "            lambda row: calculate_bleu_score(row['Human_Answer'], row[model_col]), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # ROUGE Scores\n",
    "        print(\"   → ROUGE...\")\n",
    "        rouge_scores = df.apply(\n",
    "            lambda row: calculate_rouge_scores(row['Human_Answer'], row[model_col]), \n",
    "            axis=1\n",
    "        )\n",
    "        df[f'ROUGE1_{model}'] = [score['rouge1'] for score in rouge_scores]\n",
    "        df[f'ROUGE2_{model}'] = [score['rouge2'] for score in rouge_scores]\n",
    "        df[f'ROUGEL_{model}'] = [score['rougeL'] for score in rouge_scores]\n",
    "        \n",
    "        # METEOR Score\n",
    "        print(\"   → METEOR...\")\n",
    "        df[f'METEOR_{model}'] = df.apply(\n",
    "            lambda row: calculate_meteor_score(row['Human_Answer'], row[model_col]), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "\n",
    "        \n",
    "        print(f\"   ✅ {model} evaluation completed!\")\n",
    "    \n",
    "    # ==================== AGGREGATE SCORES ====================\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"CALCULATING AGGREGATE SCORES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for model in models:\n",
    "        # Average of BLEU, ROUGE-L, and METEOR (higher is better)\n",
    "     \n",
    "        score_columns = [\n",
    "            f'BLEU_{model}',\n",
    "            f'ROUGEL_{model}',\n",
    "            f'METEOR_{model}'\n",
    "        ]\n",
    "        \n",
    "        df[f'Aggregate_Score_{model}'] = df[score_columns].mean(axis=1).round(4)\n",
    "        print(f\"✅ Aggregate score calculated for {model}\")\n",
    "    \n",
    "    # ==================== SUMMARY STATISTICS ====================\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"GENERATING SUMMARY STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    summary_data = {\n",
    "        'Model': [],\n",
    "        'Avg_BLEU': [],\n",
    "        'Avg_ROUGE-1': [],\n",
    "        'Avg_ROUGE-2': [],\n",
    "        'Avg_ROUGE-L': [],\n",
    "        'Avg_METEOR': [],\n",
    "        'Avg_Aggregate_Score': []\n",
    "    }\n",
    "    \n",
    "    for model in models:\n",
    "        summary_data['Model'].append(model)\n",
    "        summary_data['Avg_BLEU'].append(round(df[f'BLEU_{model}'].mean(), 4))\n",
    "        summary_data['Avg_ROUGE-1'].append(round(df[f'ROUGE1_{model}'].mean(), 4))\n",
    "        summary_data['Avg_ROUGE-2'].append(round(df[f'ROUGE2_{model}'].mean(), 4))\n",
    "        summary_data['Avg_ROUGE-L'].append(round(df[f'ROUGEL_{model}'].mean(), 4))\n",
    "        summary_data['Avg_METEOR'].append(round(df[f'METEOR_{model}'].mean(), 4))\n",
    "        \n",
    "        \n",
    "        summary_data['Avg_Aggregate_Score'].append(round(df[f'Aggregate_Score_{model}'].mean(), 4))\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # ==================== SAVE RESULTS ====================\n",
    "    \n",
    "    output_file = excel_file.replace('.xlsx', '_evaluated.xlsx')\n",
    "    \n",
    "    print(f\"\\n💾 Saving results to: {output_file}\")\n",
    "    \n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, sheet_name='Detailed_Results', index=False)\n",
    "        summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "    \n",
    "    print(f\"✅ Results saved successfully!\\n\")\n",
    "    \n",
    "    # ==================== DISPLAY RESULTS ====================\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    # Display best performing model\n",
    "    best_model_idx = summary_df['Avg_Aggregate_Score'].idxmax()\n",
    "    best_model = summary_df.loc[best_model_idx, 'Model']\n",
    "    best_score = summary_df.loc[best_model_idx, 'Avg_Aggregate_Score']\n",
    "    print(f\"\\n Best Performing Model: {best_model} (Aggregate Score: {best_score})\")\n",
    "    \n",
    "    return df, summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f646737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 51 rows from Excel\n",
      " Columns: ['Question', 'Human_Answer', 'Gpt_Answer', 'Gemma_Answer', 'Llama_Answer']\n",
      " Standardized columns: ['Question', 'Human_Answer', 'GPT_Answer', 'Gemma_Answer', 'Llama_Answer']\n",
      "\n",
      " Found models: ['GPT', 'Gemma', 'Llama']\n",
      "\n",
      "============================================================\n",
      "CALCULATING METRICS\n",
      "============================================================\n",
      "\n",
      " Evaluating GPT...\n",
      "   → BLEU...\n",
      "   → ROUGE...\n",
      "   → METEOR...\n",
      "   ✅ GPT evaluation completed!\n",
      "\n",
      " Evaluating Gemma...\n",
      "   → BLEU...\n",
      "   → ROUGE...\n",
      "   → METEOR...\n",
      "   ✅ Gemma evaluation completed!\n",
      "\n",
      " Evaluating Llama...\n",
      "   → BLEU...\n",
      "   → ROUGE...\n",
      "   → METEOR...\n",
      "   ✅ Llama evaluation completed!\n",
      "\n",
      "============================================================\n",
      "CALCULATING AGGREGATE SCORES\n",
      "============================================================\n",
      "✅ Aggregate score calculated for GPT\n",
      "✅ Aggregate score calculated for Gemma\n",
      "✅ Aggregate score calculated for Llama\n",
      "\n",
      "============================================================\n",
      "GENERATING SUMMARY STATISTICS\n",
      "============================================================\n",
      "\n",
      "💾 Saving results to: test_Q_A_with_oss_answers_evaluated.xlsx\n",
      "✅ Results saved successfully!\n",
      "\n",
      "============================================================\n",
      "SUMMARY STATISTICS\n",
      "============================================================\n",
      "Model  Avg_BLEU  Avg_ROUGE-1  Avg_ROUGE-2  Avg_ROUGE-L  Avg_METEOR  Avg_Aggregate_Score\n",
      "  GPT    0.0636       0.3407       0.1479       0.2580      0.3183               0.2133\n",
      "Gemma    0.0639       0.3178       0.1459       0.2480      0.3187               0.2102\n",
      "Llama    0.0626       0.3350       0.1488       0.2622      0.3231               0.2160\n",
      "\n",
      " Best Performing Model: Llama (Aggregate Score: 0.216)\n"
     ]
    }
   ],
   "source": [
    "excel_file_path='test_Q_A_with_oss_answers.xlsx'\n",
    "\n",
    "detailed_results, summary = evaluate_answers(\n",
    "    excel_file_path,\n",
    "    sheet_name='Sheet1',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "def create_visualizations(summary_df, detailed_df, output_folder='plots'):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualizations for presentation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    summary_df : DataFrame\n",
    "        Summary statistics dataframe\n",
    "    detailed_df : DataFrame\n",
    "        Detailed results dataframe\n",
    "    output_folder : str\n",
    "        Folder to save plots\n",
    "    \"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    models = summary_df['Model'].tolist()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CREATING VISUALIZATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ==================== PLOT 1: Overall Performance Comparison ====================\n",
    "    print(\"\\n Creating Plot 1: Overall Performance Comparison...\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    x = np.arange(len(models))\n",
    "    width = 0.15\n",
    "    \n",
    "    metrics = ['Avg_BLEU', 'Avg_ROUGE-L', 'Avg_METEOR', 'Avg_Aggregate_Score']\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "    \n",
    "    for i, (metric, color) in enumerate(zip(metrics, colors)):\n",
    "        values = summary_df[metric].values\n",
    "        ax.bar(x + i*width, values, width, label=metric.replace('Avg_', ''), color=color, alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Overall Performance Comparison Across Models', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x + width * 1.5)\n",
    "    ax.set_xticklabels(models)\n",
    "    ax.legend(loc='upper left', framealpha=0.9)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_folder}/01_overall_performance.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"    Saved: {output_folder}/01_overall_performance.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # ==================== PLOT 2: Radar Chart ====================\n",
    "    print(\"\\n Creating Plot 2: Radar Chart...\")\n",
    "    \n",
    "    from math import pi\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "    \n",
    "    metrics = ['Avg_BLEU', 'Avg_ROUGE-1', 'Avg_ROUGE-2', 'Avg_ROUGE-L', 'Avg_METEOR']\n",
    "    num_vars = len(metrics)\n",
    "    angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    colors_radar = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#96CEB4']\n",
    "    \n",
    "    for idx, model in enumerate(models):\n",
    "        values = summary_df[summary_df['Model'] == model][metrics].values.flatten().tolist()\n",
    "        values += values[:1]\n",
    "        \n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=model, color=colors_radar[idx % len(colors_radar)])\n",
    "        ax.fill(angles, values, alpha=0.15, color=colors_radar[idx % len(colors_radar)])\n",
    "    \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels([m.replace('Avg_', '').replace('-', '\\n') for m in metrics], fontsize=10)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('Multi-Metric Performance Comparison\\n(Radar Chart)', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_folder}/02_radar_chart.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"    Saved: {output_folder}/02_radar_chart.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # ==================== PLOT 3: Heatmap ====================\n",
    "    print(\"\\n Creating Plot 3: Heatmap...\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    heatmap_data = summary_df[['Model', 'Avg_BLEU', 'Avg_ROUGE-1', 'Avg_ROUGE-2', \n",
    "                                'Avg_ROUGE-L', 'Avg_METEOR', 'Avg_Aggregate_Score']]\n",
    "    heatmap_data = heatmap_data.set_index('Model')\n",
    "    \n",
    "    sns.heatmap(heatmap_data.T, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                center=0.5, linewidths=1, cbar_kws={'label': 'Score'},\n",
    "                vmin=0, vmax=1)\n",
    "    \n",
    "    plt.title('Performance Heatmap Across All Metrics', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Models', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Metrics', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_folder}/03_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"    Saved: {output_folder}/03_heatmap.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # ==================== PLOT 4: Box Plot (Score Distribution) ====================\n",
    "    print(\"\\n Creating Plot 4: Score Distribution (Box Plot)...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('Score Distribution Across Models', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    metrics_box = ['BLEU', 'ROUGEL', 'METEOR', 'Aggregate_Score']\n",
    "    metric_names = ['BLEU Score', 'ROUGE-L Score', 'METEOR Score', 'Aggregate Score']\n",
    "    \n",
    "    for idx, (metric, name) in enumerate(zip(metrics_box, metric_names)):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        \n",
    "        data_to_plot = []\n",
    "        for model in models:\n",
    "            col_name = f'{metric}_{model}'\n",
    "            if col_name in detailed_df.columns:\n",
    "                data_to_plot.append(detailed_df[col_name].values)\n",
    "        \n",
    "        bp = ax.boxplot(data_to_plot, labels=models, patch_artist=True,\n",
    "                        notch=True, showmeans=True)\n",
    "        \n",
    "        # Color the boxes\n",
    "        colors_box = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#96CEB4']\n",
    "        for patch, color in zip(bp['boxes'], colors_box):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "        \n",
    "        ax.set_title(name, fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Score', fontsize=10)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        ax.set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_folder}/04_boxplot_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"    Saved: {output_folder}/04_boxplot_distribution.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # ==================== PLOT 5: Perplexity Comparison ====================\n",
    "    if 'Avg_Perplexity' in summary_df.columns and summary_df['Avg_Perplexity'].iloc[0] != 'N/A':\n",
    "        print(\"\\n Creating Plot 5: Perplexity Comparison...\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        ppl_data = summary_df[summary_df['Avg_Perplexity'] != 'N/A'].copy()\n",
    "        ppl_data['Avg_Perplexity'] = pd.to_numeric(ppl_data['Avg_Perplexity'])\n",
    "        \n",
    "        bars = ax.bar(ppl_data['Model'], ppl_data['Avg_Perplexity'], \n",
    "                     color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#96CEB4'][:len(ppl_data)],\n",
    "                     alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Perplexity', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Perplexity Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{height:.2f}',\n",
    "                   ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_folder}/05_perplexity_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"    Saved: {output_folder}/05_perplexity_comparison.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "    # ==================== PLOT 6: Ranking Chart ====================\n",
    "    print(\"\\n📊 Creating Plot 6: Model Ranking...\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Create ranking based on aggregate score\n",
    "    ranking_df = summary_df.sort_values('Avg_Aggregate_Score', ascending=False).reset_index(drop=True)\n",
    "    ranking_df['Rank'] = range(1, len(ranking_df) + 1)\n",
    "    \n",
    "    colors_rank = ['#FFD700', '#C0C0C0', '#CD7F32', '#87CEEB', '#90EE90']  # Gold, Silver, Bronze, etc.\n",
    "    \n",
    "    bars = ax.barh(ranking_df['Model'], ranking_df['Avg_Aggregate_Score'], \n",
    "                   color=colors_rank[:len(ranking_df)], alpha=0.8)\n",
    "    \n",
    "    # Add rank labels\n",
    "    for idx, (score, model, rank) in enumerate(zip(ranking_df['Avg_Aggregate_Score'], \n",
    "                                                     ranking_df['Model'], \n",
    "                                                     ranking_df['Rank'])):\n",
    "        ax.text(score + 0.01, idx, f'#{rank} - {score:.4f}', \n",
    "               va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Aggregate Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Models', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Model Ranking by Aggregate Performance', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlim(0, 1.1)\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_folder}/06_model_ranking.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"    Saved: {output_folder}/06_model_ranking.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    # ==================== PLOT 7: ROUGE Variants Comparison ====================\n",
    "    print(\"\\n📊 Creating Plot 7: ROUGE Variants Comparison...\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    x = np.arange(len(models))\n",
    "    width = 0.25\n",
    "    \n",
    "    rouge1 = summary_df['Avg_ROUGE-1'].values\n",
    "    rouge2 = summary_df['Avg_ROUGE-2'].values\n",
    "    rougeL = summary_df['Avg_ROUGE-L'].values\n",
    "    \n",
    "    ax.bar(x - width, rouge1, width, label='ROUGE-1', color='#FF6B6B', alpha=0.8)\n",
    "    ax.bar(x, rouge2, width, label='ROUGE-2', color='#4ECDC4', alpha=0.8)\n",
    "    ax.bar(x + width, rougeL, width, label='ROUGE-L', color='#45B7D1', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('ROUGE Score', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('ROUGE Variants Comparison (1-gram, 2-gram, LCS)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models)\n",
    "    ax.legend(framealpha=0.9)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_folder}/07_rouge_variants.png', dpi=300, bbox_inches='tight')\n",
    "    print(f\"    Saved: {output_folder}/07_rouge_variants.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\" ALL VISUALIZATIONS SAVED IN '{output_folder}/' FOLDER\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n Generated Plots:\")\n",
    "    print(\"   1. Overall Performance Comparison (Bar Chart)\")\n",
    "    print(\"   2. Multi-Metric Radar Chart\")\n",
    "    print(\"   3. Performance Heatmap\")\n",
    "    print(\"   4. Score Distribution (Box Plots)\")\n",
    "    print(\"   6. Model Ranking Chart\")\n",
    "    print(\"   7. ROUGE Variants Comparison\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ed3cb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rohan\\anaconda3\\envs\\rag\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fddc749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING VISUALIZATIONS\n",
      "============================================================\n",
      "\n",
      "📊 Creating Plot 1: Overall Performance Comparison...\n",
      "   ✅ Saved: presentation_plots/01_overall_performance.png\n",
      "\n",
      "📊 Creating Plot 2: Radar Chart...\n",
      "   ✅ Saved: presentation_plots/02_radar_chart.png\n",
      "\n",
      "📊 Creating Plot 3: Heatmap...\n",
      "   ✅ Saved: presentation_plots/03_heatmap.png\n",
      "\n",
      "📊 Creating Plot 4: Score Distribution (Box Plot)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_19052\\2219389866.py:131: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  bp = ax.boxplot(data_to_plot, labels=models, patch_artist=True,\n",
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_19052\\2219389866.py:131: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  bp = ax.boxplot(data_to_plot, labels=models, patch_artist=True,\n",
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_19052\\2219389866.py:131: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  bp = ax.boxplot(data_to_plot, labels=models, patch_artist=True,\n",
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_19052\\2219389866.py:131: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  bp = ax.boxplot(data_to_plot, labels=models, patch_artist=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Saved: presentation_plots/04_boxplot_distribution.png\n",
      "\n",
      "📊 Creating Plot 6: Model Ranking...\n",
      "   ✅ Saved: presentation_plots/06_model_ranking.png\n",
      "\n",
      "📊 Creating Plot 7: ROUGE Variants Comparison...\n",
      "   ✅ Saved: presentation_plots/07_rouge_variants.png\n",
      "\n",
      "============================================================\n",
      "✅ ALL VISUALIZATIONS SAVED IN 'presentation_plots/' FOLDER\n",
      "============================================================\n",
      "\n",
      "📊 Generated Plots:\n",
      "   1. Overall Performance Comparison (Bar Chart)\n",
      "   2. Multi-Metric Radar Chart\n",
      "   3. Performance Heatmap\n",
      "   4. Score Distribution (Box Plots)\n",
      "   5. Perplexity Comparison (if calculated)\n",
      "   6. Model Ranking Chart\n",
      "   7. ROUGE Variants Comparison\n"
     ]
    }
   ],
   "source": [
    "create_visualizations(summary, detailed_results, output_folder='presentation_plots')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
