{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a089d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import openai\n",
    "import os\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34a0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_chromadb(persist_directory=\"./chroma_db\", collection_name=\"policies\"):\n",
    "    \"\"\"\n",
    "    Initialize ChromaDB client and create/get collection.\n",
    "    \n",
    "    Args:\n",
    "        persist_directory: Local directory to persist the database\n",
    "        collection_name: Name of the collection\n",
    "    \n",
    "    Returns:\n",
    "        ChromaDB collection object\n",
    "    \"\"\"\n",
    "    # Create persist directory if it doesn't exist\n",
    "    os.makedirs(persist_directory, exist_ok=True)\n",
    "    \n",
    "    # Initialize ChromaDB client with persistence\n",
    "    client = chromadb.PersistentClient(path=persist_directory)\n",
    "    \n",
    "    print(f\"‚úì ChromaDB initialized at: {persist_directory}\")\n",
    "    \n",
    "    # Get or create collection\n",
    "    try:\n",
    "        # Try to get existing collection\n",
    "        collection = client.get_collection(name=collection_name)\n",
    "        print(f\"‚úì Retrieved existing collection: {collection_name}\")\n",
    "        print(f\"  Current documents: {collection.count()}\")\n",
    "    except:\n",
    "        # Create new collection if doesn't exist\n",
    "        collection = client.create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"description\": \"UF Policy documents with embeddings\"}\n",
    "        )\n",
    "        print(f\"‚úì Created new collection: {collection_name}\")\n",
    "    \n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e71add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_model(model_name=\"BAAI/bge-small-en-v1.5\"):\n",
    "    \"\"\"\n",
    "    Load BGE embedding model from HuggingFace.\n",
    "    \n",
    "    Available BGE models:\n",
    "    - BAAI/bge-small-en-v1.5 (fastest, 384 dimensions)\n",
    "    - BAAI/bge-base-en-v1.5 (balanced, 768 dimensions)\n",
    "    - BAAI/bge-large-en-v1.5 (best quality, 1024 dimensions)\n",
    "    \n",
    "    Args:\n",
    "        model_name: HuggingFace model identifier\n",
    "    \n",
    "    Returns:\n",
    "        SentenceTransformer model\n",
    "    \"\"\"\n",
    "    print(f\"Loading embedding model: {model_name}\")\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print(f\"‚úì Model loaded successfully!\")\n",
    "    print(f\"  Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce31143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chromadb(collection, model, query_text, n_results=5, filter_by_type=None):\n",
    "    \"\"\"\n",
    "    Query ChromaDB with a text query.\n",
    "    \n",
    "    Args:\n",
    "        collection: ChromaDB collection\n",
    "        model: SentenceTransformer model for query embedding\n",
    "        query_text: Query string\n",
    "        n_results: Number of results to return\n",
    "        filter_by_type: Filter results by policy type (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Query results\n",
    "    \"\"\"\n",
    "    # Create query embedding\n",
    "    query_embedding = model.encode([query_text])[0].tolist()\n",
    "    \n",
    "    # Prepare filter\n",
    "    where_filter = None\n",
    "    if filter_by_type:\n",
    "        where_filter = {\"type\": {\"$eq\": filter_by_type}}\n",
    "    \n",
    "    # Query ChromaDB\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results,\n",
    "        where=where_filter\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_pipeline(\n",
    "                  persist_directory=\"./chroma_db\",\n",
    "                  collection_name=\"policies\",\n",
    "                  model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "                  include_types=None,\n",
    "                  ):\n",
    "    \"\"\"\n",
    "    Main pipeline to load data, create embeddings, and store in ChromaDB.\n",
    "    \n",
    "    Args:\n",
    "        excel_file: Path to Excel file\n",
    "        persist_directory: ChromaDB storage directory\n",
    "        collection_name: Name of ChromaDB collection\n",
    "        model_name: BGE model name\n",
    "        include_types: List of types to include (e.g., ['Policy', 'Regulation'])\n",
    "        overwrite: If True, delete existing collection and create new one\n",
    "    \n",
    "    Returns:\n",
    "        collection: ChromaDB collection object\n",
    "        model: Embedding model\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Step 2: Load embedding model\n",
    "    print(f\"\\nStep 2: Loading embedding model...\")\n",
    "    model = load_embedding_model(model_name)\n",
    "    \n",
    "    # Step 3: Initialize ChromaDB\n",
    "    print(f\"\\nStep 3: Initializing ChromaDB...\")\n",
    "    \n",
    "    collection = initialize_chromadb(persist_directory, collection_name)\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úì PIPELINE COMPLETE!\")\n",
    "    print(f\"‚úì Total documents in collection: {collection.count()}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return collection, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bbead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Loading embedding model...\n",
      "Loading embedding model: BAAI/bge-base-en-v1.5\n",
      "‚úì Model loaded successfully!\n",
      "  Embedding dimension: 768\n",
      "\n",
      "Step 3: Initializing ChromaDB...\n",
      "‚úì ChromaDB initialized at: ./chroma_db\n",
      "‚úì Retrieved existing collection: policies\n",
      "  Current documents: 1887\n",
      "\n",
      "================================================================================\n",
      "‚úì PIPELINE COMPLETE!\n",
      "‚úì Total documents in collection: 1887\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "collection, model = main_pipeline(\n",
    "                persist_directory=\"./chroma_db\",\n",
    "                collection_name=\"policies\",\n",
    "    model_name=\"BAAI/bge-base-en-v1.5\"  # Better quality\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca839e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['Working_Safely_and_Maintaining_Workplace_Health_Standards_3_1520',\n",
       "   'Furlough_Policy_(includes_UFF_Faculty_MOU)_2_1853',\n",
       "   'Paid_Family_Leave_7_1595']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['. Employees should not return to work until symptoms have improved. Employees must follow all department reporting procedures for absences, including accurately reporting their work time and absence from the office in myUFL. During the absence, employees may work from home, if approved, and shall use accrued sick leave or leave without pay if unable to work. In situations in which the reason for the absence is due to an employee‚Äôs serious health condition, the absence may be covered by the Family Medical Leave Act (FMLA) . Employees must practice and maintain personal hygiene to help ensure a healthy workplace. Strategies to accomplish this include: Washing hands to aid in keeping employees healthy and preventing the spread of illness to co-workers. All employees should adhere to the CDC recommendations on handwashing: Wash your hands often with soap and water for at least 20 seconds especially after you have been in a public place or after blowing your nose, coughing or sneezing',\n",
       "   '. Policy Statement A furlough is a mandatory unpaid partial or full leave of absence from work. The University shall consider the availability and feasibility of other cost‚Äêsaving measures before implementing furloughs',\n",
       "   '. 4.3 Paid Medical Leave Eligibility for Employee Illness/Injury Eligibility An employee must qualify for and go on continuous FMLA leave A healthcare provider certifies that the period of continuous medically necessary absence will be at least three (3) or more weeks (15 or more working days) for the employee‚Äôs serious illness or injury The illness or injury prevents the employee from performing the material and substantial duties of their UF position The illness or injury prevents the employee from performing majority of activities of daily living The employee must be under the ongoing care of a Physician in the appropriate specialty as determined by UF Central Leave']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'category': 'Human Resources',\n",
       "    'title': 'Working Safely and Maintaining Workplace Health Standards',\n",
       "    'type': 'Policy'},\n",
       "   {'category': 'Human Resources',\n",
       "    'type': 'Policy',\n",
       "    'title': 'Furlough Policy (includes UFF Faculty MOU)'},\n",
       "   {'category': 'Human Resources',\n",
       "    'type': 'Policy',\n",
       "    'title': 'Paid Family Leave'}]],\n",
       " 'distances': [[0.5599740743637085, 0.5678935050964355, 0.5807972550392151]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7eac0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_openai_client(api_key: str, base_url: str = 'https://api.ai.it.ufl.edu'):\n",
    "    \"\"\"\n",
    "    Initialize OpenAI client with custom base URL.\n",
    "    \n",
    "    Args:\n",
    "        api_key: Your OpenAI API key\n",
    "        base_url: Custom base URL for API (default: UF API endpoint)\n",
    "    \n",
    "    Returns:\n",
    "        OpenAI client object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = openai.OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=base_url\n",
    "        )\n",
    "        \n",
    "        print('‚úì OpenAI client created successfully')\n",
    "        print(f'  Base URL: {base_url}')\n",
    "        print(f'  Client type: {type(client)}')\n",
    "        \n",
    "        # Sanity checks\n",
    "        has_chat = hasattr(client, 'chat')\n",
    "        print(f'  Has chat attribute: {has_chat}')\n",
    "        \n",
    "        if has_chat:\n",
    "            has_completions = hasattr(client.chat, 'completions')\n",
    "            print(f'  Has completions attribute: {has_completions}')\n",
    "        \n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error initializing OpenAI client: {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57987876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Any\n",
    "def prepare_context_from_results(query_results: Dict[str, Any]) -> tuple:\n",
    "    \"\"\"\n",
    "    Prepare context and metadata from ChromaDB query results.\n",
    "    \n",
    "    Args:\n",
    "        query_results: Dictionary from ChromaDB query (with ids, documents, metadatas, distances)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (context_text, source_documents)\n",
    "    \"\"\"\n",
    "    # Extract documents and metadata\n",
    "    documents = query_results['documents'][0]\n",
    "    metadatas = query_results['metadatas'][0]\n",
    "    distances = query_results['distances'][0]\n",
    "    \n",
    "    # Build context text\n",
    "    context_parts = []\n",
    "    source_documents = []\n",
    "    \n",
    "    for i, (doc, metadata, distance) in enumerate(zip(documents, metadatas, distances), 1):\n",
    "        # Add document to context with reference number\n",
    "        context_parts.append(f\"[Document {i}]\")\n",
    "        context_parts.append(f\"Title: {metadata['title']}\")\n",
    "        context_parts.append(f\"Type: {metadata['type']}\")\n",
    "        context_parts.append(f\"Category: {metadata['category']}\")\n",
    "        context_parts.append(f\"Content: {doc}\")\n",
    "        context_parts.append(\"\")  # Empty line between documents\n",
    "        \n",
    "        # Store source information\n",
    "        source_documents.append({\n",
    "            'title': metadata['title'],\n",
    "            'type': metadata['type'],\n",
    "            'category': metadata['category'],\n",
    "            'distance': distance,\n",
    "            'link': metadata.get('link', 'N/A')\n",
    "        })\n",
    "    \n",
    "    context_text = \"\\n\".join(context_parts)\n",
    "    \n",
    "    return context_text, source_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "941f8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_openai_with_context(\n",
    "    client,\n",
    "    question: str,\n",
    "    query_results: Dict[str, Any],\n",
    "    model: str = \"gpt-oss-120b\",\n",
    "    temperature: float = 0.1,\n",
    "    max_tokens: int = 1000\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Query OpenAI with context from ChromaDB results.\n",
    "    \n",
    "    Args:\n",
    "        client: OpenAI client object\n",
    "        question: User's question\n",
    "        query_results: Results from ChromaDB query\n",
    "        model: Model name (e.g., 'gpt-4', 'gpt-3.5-turbo')\n",
    "        temperature: Sampling temperature (0-2, lower is more focused)\n",
    "        max_tokens: Maximum tokens in response\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with answer and source documents\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare context from query results\n",
    "        context_text, source_documents = prepare_context_from_results(query_results)\n",
    "        print(context_text,source_documents)\n",
    "        \n",
    "        # Create system prompt\n",
    "        system_prompt = \"\"\"You are a helpful assistant that answers questions based ONLY on the provided context documents.\n",
    "\n",
    "IMPORTANT RULES:\n",
    "1. Answer ONLY using information from the provided documents\n",
    "2. Do NOT use any external knowledge or information not present in the documents\n",
    "3. If the answer is not in the provided documents, say \"I cannot find this information in the provided documents\"\n",
    "4. Cite which document(s) you used by referring to [Document N] format\n",
    "\"\"\"\n",
    "\n",
    "        # Create user prompt with context\n",
    "        user_prompt = f\"\"\"Context Documents:\n",
    "{context_text}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Please answer the question using ONLY the information from the context documents above. Do not use any external knowledge.\"\"\"\n",
    "\n",
    "        # Call OpenAI API\n",
    "        print(f\"\\nü§ñ Querying {model}...\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        \n",
    "        # Extract answer\n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        # Prepare result\n",
    "        result = {\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'source_documents': source_documents,\n",
    "            'model': model,\n",
    "            'temperature': temperature,\n",
    "            'tokens_used': {\n",
    "                'prompt': response.usage.prompt_tokens,\n",
    "                'completion': response.usage.completion_tokens,\n",
    "                'total': response.usage.total_tokens\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(\"‚úì Response received successfully\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error querying OpenAI: {e}\")\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': f\"Error: {str(e)}\",\n",
    "            'source_documents': [],\n",
    "            'model': model\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7e34b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_text = \"uf teaching assistant pay sat and sunday?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7de8ebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì OpenAI client created successfully\n",
      "  Base URL: https://api.ai.it.ufl.edu\n",
      "  Client type: <class 'openai.OpenAI'>\n",
      "  Has chat attribute: True\n",
      "  Has completions attribute: True\n",
      "[Document 1]\n",
      "Title: On-Call Pay and Callbacks\n",
      "Type: Policy\n",
      "Category: Human Resources\n",
      "Content: . An employee who is on-call on Saturday, Sunday, and/or a university holiday or official closing may be paid at the rate of one-third (1/3) of the UF Hourly minimum wage for TEAMS employees per hour for each hour they are required to be available. Callback pay for non-exempt employees is mandatory and is not awarded on a discretionary basis. Callback pay occurs when an employee is ‚Äúcalled back‚Äù to perform work beyond the employee‚Äôs scheduled hours of work for that day, a minimum payment may be required. Non-exempt TEAMS employees who are called back to campus or other appropriate worksites will be credited with either two hours or the actual time worked plus traveling time to and from the employee‚Äôs home‚Äîwhichever is greater. The two hour minimum payment is applicable to employees who are required to report to campus or work site\n",
      "\n",
      "[Document 2]\n",
      "Title: Premium Pay for Holidays and University Emergencies\n",
      "Type: Policy\n",
      "Category: Human Resources\n",
      "Content: . The following security role is required in order to enter premium pay: UF_TL_DEPT_PROCESSOR * The total amount an employee will receive when he or she is in a Premium Pay Hourly status is 1.5 times his or her normal rate of pay. This includes the employee‚Äôs regular rate, plus the premium which is calculated at ¬Ω the normal rate. For example, if an employee with a regular rate of $20 is paid 8 hours of Premium Pay Hourly, his or her regular compensation would be 8 hours x 20, and his or her Premium would be 8 hours x 20 x .5. 5. Review and Adjudication The following is the department is responsible for overseeing implementation of and assuring compliance with this policy. This is who to contact with questions about the policy or to report suspected violations: UF Human Resources Classification & Compensation 903 W. University Ave. PO Box 115009 Gainesville, FL 32611-5009 (352) 273-2842 compensation@ufl.edu 6\n",
      "\n",
      "[Document 3]\n",
      "Title: Non-Student Hourly OPS Employment\n",
      "Type: Policy\n",
      "Category: Human Resources\n",
      "Content: . The University of Florida is considered one employer under the Fair Labor Standards Act (FLSA). OPS employees who have more than one appointment and a total FTE over 1.0 within UF require submission of the Request for Approval of Additional University Compensation (HR600) form signed by UFHR to ensure compliance with the FLSA. Non-student hourly OPS employees must be paid overtime pay at a rate of not less than one and one-half times their regular rate of pay after 40 hours of work in a workweek. They are not eligible for overtime compensatory leave. Overtime worked should be accurately reflected in the myUFL system. College/units are responsible for ensuring overtime is accurately tracked and paid. In cases where an OPS employee has multiple appointments, the college/unit in which the overtime occurs is responsible for paying overtime wages\n",
      " [{'title': 'On-Call Pay and Callbacks', 'type': 'Policy', 'category': 'Human Resources', 'distance': 0.5877289772033691, 'link': 'N/A'}, {'title': 'Premium Pay for Holidays and University Emergencies', 'type': 'Policy', 'category': 'Human Resources', 'distance': 0.6286293268203735, 'link': 'N/A'}, {'title': 'Non-Student Hourly OPS Employment', 'type': 'Policy', 'category': 'Human Resources', 'distance': 0.6647508144378662, 'link': 'N/A'}]\n",
      "\n",
      "ü§ñ Querying gpt-oss-120b...\n",
      "‚úì Response received successfully\n"
     ]
    }
   ],
   "source": [
    "client = initialize_openai_client(\n",
    "    api_key=\"sk-pgNP-BIHOtI8RPt-aC3Stg\",\n",
    "    base_url='https://api.ai.it.ufl.edu'\n",
    ")\n",
    "query_result= query_chromadb(\n",
    "    collection=collection,\n",
    "    model=model,\n",
    "    query_text=question_text,\n",
    "    n_results=3,\n",
    "    filter_by_type=\"Policy\"  # Only search Policy type\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "result = query_openai_with_context(\n",
    "    client=client,\n",
    "    question=question_text,\n",
    "    query_results=query_result,\n",
    "    model=\"gpt-oss-120b\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "585c1854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'uf teaching assistant pay sat and sunday?',\n",
       " 'answer': 'Teaching assistants who are on‚Äëcall on Saturday, Sunday (or a university holiday/official closing) are paid at a rate of **one‚Äëthird (1/3) of the UF hourly minimum wage for TEAMS employees for each hour they must be available**„ÄêDocument\\u202f1„Äë.',\n",
       " 'source_documents': [{'title': 'On-Call Pay and Callbacks',\n",
       "   'type': 'Policy',\n",
       "   'category': 'Human Resources',\n",
       "   'distance': 0.5877289772033691,\n",
       "   'link': 'N/A'},\n",
       "  {'title': 'Premium Pay for Holidays and University Emergencies',\n",
       "   'type': 'Policy',\n",
       "   'category': 'Human Resources',\n",
       "   'distance': 0.6286293268203735,\n",
       "   'link': 'N/A'},\n",
       "  {'title': 'Non-Student Hourly OPS Employment',\n",
       "   'type': 'Policy',\n",
       "   'category': 'Human Resources',\n",
       "   'distance': 0.6647508144378662,\n",
       "   'link': 'N/A'}],\n",
       " 'model': 'gpt-oss-120b',\n",
       " 'temperature': 0.1,\n",
       " 'tokens_used': {'prompt': 835, 'completion': 192, 'total': 1027}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875bcbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54caafdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
